# ğŸ“š Implementation Guide: Legal Document Analysis
*ÎŸÎ´Î·Î³ÏŒÏ‚ Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚: Î‘Î½Î¬Î»Ï…ÏƒÎ· ÎÎ¿Î¼Î¹ÎºÏÎ½ Î•Î³Î³ÏÎ¬Ï†Ï‰Î½*

## ğŸ¯ Î’Î±ÏƒÎ¹ÎºÎ¬ Î£Ï„Î¬Î´Î¹Î± Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚

### 1ï¸âƒ£ Î ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î±ÏƒÎ¯Î± & Î•Î¾ÎµÏÎµÏÎ½Î·ÏƒÎ· Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
```python
# notebook: 01_data_exploration.ipynb

# 1. Î’Î±ÏƒÎ¹ÎºÎ­Ï‚ Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎµÏ‚
import pandas as pd
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns

# 2. Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
df = pd.read_csv("data/raw/legal_cases.csv")

# 3. Î’Î±ÏƒÎ¹ÎºÎ® Î±Î½Î¬Î»Ï…ÏƒÎ·
def analyze_dataset(df: pd.DataFrame) -> Dict[str, Any]:
    """
    Î‘Î½Î¬Î»Ï…ÏƒÎ· Î²Î±ÏƒÎ¹ÎºÏÎ½ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½ Ï„Î¿Ï… dataset
    
    ÎœÎµÏ„ÏÎ¹ÎºÎ­Ï‚:
    - ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎºÎ±Ï„Î·Î³Î¿ÏÎ¹ÏÎ½
    - Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ Î¼Î®ÎºÎ¿Ï…Ï‚ ÎºÎµÎ¹Î¼Î­Î½Î¿Ï…
    - ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ ÎµÎ»Î»Î¹Ï€ÏÎ½ Ï„Î¹Î¼ÏÎ½
    """
    analysis = {
        'total_cases': len(df),
        'missing_values': df.isnull().sum(),
        'text_length_stats': df['case_text'].str.len().describe(),
        'outcome_distribution': df['case_outcome'].value_counts()
    }
    return analysis

# 4. ÎŸÏ€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·
def plot_distributions(df: pd.DataFrame) -> None:
    """
    ÎŸÏ€Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î²Î±ÏƒÎ¹ÎºÏÎ½ ÎºÎ±Ï„Î±Î½Î¿Î¼ÏÎ½
    """
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # ÎšÎ±Ï„Î±Î½Î¿Î¼Î® Î¼Î®ÎºÎ¿Ï…Ï‚ ÎºÎµÎ¹Î¼Î­Î½Î¿Ï…
    df['text_length'].hist(bins=50, ax=ax1)
    ax1.set_title('ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎœÎ®ÎºÎ¿Ï…Ï‚ ÎšÎµÎ¹Î¼Î­Î½Î¿Ï…')
    
    # ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎºÎ±Ï„Î·Î³Î¿ÏÎ¹ÏÎ½
    df['case_outcome'].value_counts().plot(kind='bar', ax=ax2)
    ax2.set_title('ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎšÎ±Ï„Î·Î³Î¿ÏÎ¹ÏÎ½')
```

### 2ï¸âƒ£ Î•Î¾Î±Î³Ï‰Î³Î® ÎÎ¿Î¼Î¹ÎºÏÎ½ Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½
```python
# notebook: 02_feature_extraction.ipynb

# 1. Î•Î¾Î±Î³Ï‰Î³Î® Î±Î½Î±Ï†Î¿ÏÏÎ½ (citations)
def extract_legal_features(text: str) -> Dict[str, Any]:
    """
    Î•Î¾Î±Î³Ï‰Î³Î® Î½Î¿Î¼Î¹ÎºÏÎ½ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½ Î±Ï€ÏŒ ÎºÎµÎ¯Î¼ÎµÎ½Î¿
    
    Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬:
    - Î‘Î½Î±Ï†Î¿ÏÎ­Ï‚ ÏƒÎµ Î½ÏŒÎ¼Î¿Ï…Ï‚
    - Î”Î¹ÎºÎ±ÏƒÏ„Î¹ÎºÎ­Ï‚ Î±Ï€Î¿Ï†Î¬ÏƒÎµÎ¹Ï‚
    - ÎÎ¿Î¼Î¹ÎºÎ¿Î¯ ÏŒÏÎ¿Î¹
    """
    features = {
        'citations': extract_citations(text),
        'legal_terms': extract_legal_terms(text),
        'case_references': extract_case_refs(text)
    }
    return features

# 2. Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½
def calculate_legal_metrics(df: pd.DataFrame) -> pd.DataFrame:
    """
    Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î½Î¿Î¼Î¹ÎºÏÎ½ Î¼ÎµÏ„ÏÎ¹ÎºÏÎ½
    
    ÎœÎµÏ„ÏÎ¹ÎºÎ­Ï‚:
    - Î Î»Î®Î¸Î¿Ï‚ Î±Î½Î±Ï†Î¿ÏÏÎ½
    - Î£Ï…Ï‡Î½ÏŒÏ„Î·Ï„Î± Î½Î¿Î¼Î¹ÎºÏÎ½ ÏŒÏÏ‰Î½
    - Î£Ï‡Î­ÏƒÎµÎ¹Ï‚ Î¼ÎµÏ„Î±Î¾Ï Ï…Ï€Î¿Î¸Î­ÏƒÎµÏ‰Î½
    """
    metrics = pd.DataFrame()
    metrics['citation_count'] = df['case_text'].apply(
        lambda x: len(extract_citations(x))
    )
    return metrics
```

### 3ï¸âƒ£ Î ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î±ÏƒÎ¯Î± Î³Î¹Î± ÎœÎ¿Î½Ï„ÎµÎ»Î¿Ï€Î¿Î¯Î·ÏƒÎ·
```python
# notebook: 03_model_preparation.ipynb

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split

def prepare_for_modeling(df: pd.DataFrame) -> Tuple[np.array, np.array]:
    """
    Î ÏÎ¿ÎµÏ„Î¿Î¹Î¼Î±ÏƒÎ¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î³Î¹Î± ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·
    
    Î”Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯Î±:
    1. ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÎºÎµÎ¹Î¼Î­Î½Î¿Ï…
    2. Vectorization
    3. Train-test split
    """
    # Vectorization
    vectorizer = TfidfVectorizer(
        max_features=5000,
        stop_words='english'
    )
    
    X = vectorizer.fit_transform(df['case_text'])
    y = df['case_outcome']
    
    return train_test_split(X, y, test_size=0.15, random_state=42)
```

### 4ï¸âƒ£ Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· & Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·
```python
# notebook: 04_model_training.ipynb

from sklearn.svm import LinearSVC
from sklearn.metrics import classification_report

def train_evaluate_model(X_train, X_test, y_train, y_test):
    """
    Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· ÎºÎ±Î¹ Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï…
    
    Î£Ï„ÏŒÏ‡Î¿Î¹:
    - Î‘ÎºÏÎ¯Î²ÎµÎ¹Î± > 75%
    - F1 Score > 0.74
    - Î§ÏÏŒÎ½Î¿Ï‚ ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚ < 10 Î»ÎµÏ€Ï„Î¬
    """
    model = LinearSVC(random_state=42)
    
    # ÎšÎ±Ï„Î±Î³ÏÎ±Ï†Î® Ï‡ÏÏŒÎ½Î¿Ï… ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚
    start_time = time.time()
    model.fit(X_train, y_train)
    train_time = time.time() - start_time
    
    # Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·
    y_pred = model.predict(X_test)
    performance = classification_report(y_test, y_pred, output_dict=True)
    
    return {
        'model': model,
        'training_time': train_time,
        'performance': performance
    }
```

## ğŸ“Š Î‘Î½Î±Î¼ÎµÎ½ÏŒÎ¼ÎµÎ½Î± Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±

### 1. ÎšÎ±Ï„Î±Î½Î¿Î¼Î® Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
```yaml
Dataset Stats:
  Total Cases: ~25,000
  Categories: 10
  Avg Text Length: ~2,500 words
  Missing Values: <1%

Expected Patterns:
  - Î‘Î½Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î¯Î± ÎºÎ±Ï„Î·Î³Î¿ÏÎ¹ÏÎ½ (60-20-20)
  - ÎœÎµÎ³Î¬Î»Î· Î´Î¹Î±ÎºÏÎ¼Î±Î½ÏƒÎ· Î¼Î®ÎºÎ¿Ï…Ï‚ ÎºÎµÎ¹Î¼Î­Î½Î¿Ï…
  - Î£Ï…ÏƒÏ‡Î­Ï„Î¹ÏƒÎ· Î¼ÎµÏ„Î±Î¾Ï Î¼Î®ÎºÎ¿Ï…Ï‚ ÎºÎ±Î¹ ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯Î±Ï‚
```

### 2. ÎÎ¿Î¼Î¹ÎºÎ¬ Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬
```yaml
Citation Patterns:
  - ~5-15 citations per document
  - Î§ÏÎ¿Î½Î¹ÎºÎ® ÎºÎ±Ï„Î±Î½Î¿Î¼Î® Î±Î½Î±Ï†Î¿ÏÏÎ½
  - Î£Ï…ÏƒÏ‡Î­Ï„Î¹ÏƒÎ· Î¼Îµ case outcome

Legal Terms:
  - Î£Ï…Ï‡Î½ÏŒÏ„Î·Ï„Î± ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ·Ï‚
  - ÎšÎ±Ï„Î·Î³Î¿ÏÎ¹Î¿Ï€Î¿Î¯Î·ÏƒÎ· ÏŒÏÏ‰Î½
  - Î£Î·Î¼Î±ÏƒÎ¹Î¿Î»Î¿Î³Î¹ÎºÎ® Î±Î½Î¬Î»Ï…ÏƒÎ·
```

### 3. Î‘Ï€ÏŒÎ´Î¿ÏƒÎ· ÎœÎ¿Î½Ï„Î­Î»Î¿Ï…
```yaml
Performance Targets:
  Accuracy: >75%
  F1 Score: >0.74
  Processing: <2s/document
  
Resource Usage:
  Memory: <4.5GB
  GPU: <80%
  Training Time: <10min
```

## ğŸ”§ Î¤ÎµÏ‡Î½Î¹ÎºÎ­Ï‚ Î ÏÎ¿Î´Î¹Î±Î³ÏÎ±Ï†Î­Ï‚

### Jupyter Notebook Setup
```python
# Î£Ï„Î·Î½ Î±ÏÏ‡Î® ÎºÎ¬Î¸Îµ notebook
%matplotlib inline
%load_ext memory_profiler
%config InlineBackend.figure_format = 'retina'

# ÎšÎ±Ï„Î±Î³ÏÎ±Ï†Î® Ï‡ÏÏŒÎ½Î¿Ï… ÎºÎ±Î¹ Î¼Î½Î®Î¼Î·Ï‚
from memory_profiler import profile

@profile
def process_function():
    pass
```

### Data Processing Pipeline
```python
# Î¤Ï…Ï€Î¹ÎºÎ® ÏÎ¿Î® ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚
def process_legal_document(text: str) -> Dict[str, Any]:
    """
    Î Î»Î®ÏÎ·Ï‚ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î½Î¿Î¼Î¹ÎºÎ¿Ï ÎºÎµÎ¹Î¼Î­Î½Î¿Ï…
    
    Î’Î®Î¼Î±Ï„Î±:
    1. ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ & Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±
    2. Î•Î¾Î±Î³Ï‰Î³Î® Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½
    3. Î‘Î½Î¬Î»Ï…ÏƒÎ· & Î¼ÎµÏ„ÏÎ¹ÎºÎ­Ï‚
    """
    clean_text = preprocess_text(text)
    features = extract_features(clean_text)
    metrics = calculate_metrics(features)
    
    return {
        'features': features,
        'metrics': metrics
    }
```

## ğŸ“ˆ Î Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ· Î ÏÎ¿ÏŒÎ´Î¿Ï…

### ÎœÎµÏ„ÏÎ¹ÎºÎ­Ï‚ Î‘Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚
```python
def track_performance(func):
    """
    Decorator Î³Î¹Î± Ï€Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ· Î±Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚
    """
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        execution_time = time.time() - start_time
        
        print(f"Execution time: {execution_time:.2f} seconds")
        print(f"Memory usage: {get_memory_usage():.2f} MB")
        
        return result
    return wrapper
```

### Î‘Î½Î±Ï†Î¿ÏÎ¬ Î ÏÎ¿ÏŒÎ´Î¿Ï…
```markdown
# Progress Report [Date]

## ÎœÎµÏ„ÏÎ¹ÎºÎ­Ï‚
- Î‘ÎºÏÎ¯Î²ÎµÎ¹Î±: X%
- F1 Score: X
- Î§ÏÏŒÎ½Î¿Ï‚ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚: Xs/document

## Î•Ï€ÏŒÎ¼ÎµÎ½Î± Î’Î®Î¼Î±Ï„Î±
1. [Î•Ï€ÏŒÎ¼ÎµÎ½Î· ÎµÏÎ³Î±ÏƒÎ¯Î±]
2. [Î ÏÎ¿Ï„ÎµÏÎ±Î¹ÏŒÏ„Î·Ï„ÎµÏ‚]
```